### Controlling the Browser with Selenium
Selenium lets Python directly control the browser by programmatically clicking links and filling in forms, just as a human user would. Using Selenium, you can interact with web pages in a much more advanced way than with requests and Beautiful Soup; but because it launches a web browser, it’s a bit slower and hard to run in the background.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Still, if you need to interact with a web page in a way that, for instance, depends on the JavaScript code that updates the page, you’ll need to use Selenium instead of requests. That’s because major e-commerce websites such as Amazon almost certainly have software systems to recognize traffic that they suspect is a script harvesting their info or signing up for multiple free accounts. These sites may refuse to serve pages to you after a while, breaking any scripts you’ve made. Selenium is much more likely than requests to function on these sites long term.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A major “tell” to websites that you’re using a script is the user-agent string, which identifies the web browser and is included in all HTTP requests. For example, the user-agent string for the requests module is 
something like `'python-requests/X.XX.X'`. You can visit a site such as _https://www.whatsmyua.info_ to see your user-agent string. Using Selenium, you’re much more likely to pass for human, because not only is Selenium’s user agent the same as a regular browser (for instance, `'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0')`, but it has the same traffic patterns: a Selenium-controlled browser will download images, advertisements, cookies, and privacy-invading trackers just like a regular browser. However, websites can still find ways to detect Selenium, and major ticketing and e-commerce websites often block it to prevent the web scraping of their pages.
